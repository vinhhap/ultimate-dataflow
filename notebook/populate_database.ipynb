{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlalchemy\n",
    "import pandas\n",
    "from faker import Faker\n",
    "import uuid\n",
    "import random\n",
    "import sys\n",
    "import typing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source_sink.rdbms.rdbms_connector import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = ['something', 'awsome', None]\n",
    "test2_list = [1, 2, 3, 100000, None]\n",
    "test3_list = [1.212, 1.4444, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_records(records_num: int) -> pandas.DataFrame:\n",
    "    faker = Faker()\n",
    "    list_records = list()\n",
    "    for i in range(records_num):\n",
    "        record = dict()\n",
    "        record['id'] = str(uuid.uuid4())\n",
    "        record['name'] = faker.name()\n",
    "        record['address'] = faker.address()\n",
    "        record['message'] = faker.sentence()\n",
    "        record['email'] = faker.email()\n",
    "        record['dob'] = faker.date_of_birth()\n",
    "        record['test4'] = faker.sentence()\n",
    "        record['created_at'] = faker.date_time()\n",
    "        record['updated_at'] = faker.date_time()\n",
    "        list_records.append(record)\n",
    "    df = pandas.DataFrame(list_records)\n",
    "    df['test'] = np.random.choice(test_list, size=len(df))\n",
    "    df['test2'] = np.random.choice(test2_list, size=len(df))\n",
    "    df['test3'] = np.random.choice(test3_list, size=len(df))\n",
    "    df = df.convert_dtypes(dtype_backend='pyarrow')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conn_info(conn_file: str) -> ConnectionInfo:\n",
    "    conn_file = open(conn_file, 'r')\n",
    "    conn_info = json.loads(conn_file.read())\n",
    "    conn_file.close()\n",
    "    return ConnectionInfo(**conn_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(run_arg: dict) -> None:\n",
    "    conn_info = run_arg['conn_info']\n",
    "    table_name = run_arg['table_name']\n",
    "    db_type = run_arg['db_type']\n",
    "    records_num = run_arg['records_num']\n",
    "    connector = db_type(conn_info=conn_info)\n",
    "    conn = connector.get_database_connection()\n",
    "    df = generate_fake_records(records_num)\n",
    "    df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "    connector.close_engine()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_info_oracle = read_conn_info('../secrets/oracle-connection.json')\n",
    "conn_str_oracle = OracleConnector(conn_info=conn_info_oracle).conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql $conn_str_oracle\n",
    "create table test.test_table (\n",
    "    id varchar2(36) NOT NULL PRIMARY KEY,\n",
    "    name varchar2(100),\n",
    "    address varchar2(500),\n",
    "    message varchar2(1000),\n",
    "    email varchar2(100),\n",
    "    test varchar2(100),\n",
    "    dob date,\n",
    "    test2 number,\n",
    "    test3 float,\n",
    "    test4 clob,\n",
    "    created_at timestamp,\n",
    "    updated_at timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [{\n",
    "    \"conn_info\": conn_info_oracle,\n",
    "    \"table_name\": \"test_table\",\n",
    "    \"db_type\": OracleConnector,\n",
    "    \"records_num\": 100000\n",
    "} for l in range(10)]\n",
    "for o in inputs:\n",
    "    insert_data(o)\n",
    "    print(\"100000 rows inserted\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_info_postgres = read_conn_info('../secrets/postgres-connection.json')\n",
    "conn_str_postgres = PostgresConnector(conn_info=conn_info_postgres).conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql $conn_str_postgres\n",
    "create table test_table (\n",
    "    id char(36) NOT NULL PRIMARY KEY,\n",
    "    name varchar(100),\n",
    "    address varchar(500),\n",
    "    message varchar(1000),\n",
    "    email varchar(100),\n",
    "    test varchar(100),\n",
    "    dob date,\n",
    "    test2 bigint,\n",
    "    test3 float,\n",
    "    test4 text,\n",
    "    created_at timestamp,\n",
    "    updated_at timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n"
     ]
    }
   ],
   "source": [
    "inputs = [{\n",
    "    \"conn_info\": conn_info_postgres,\n",
    "    \"table_name\": \"test_table\",\n",
    "    \"db_type\": PostgresConnector,\n",
    "    \"records_num\": 100000\n",
    "} for l in range(10)]\n",
    "for o in inputs:\n",
    "    insert_data(o)\n",
    "    print(\"100000 rows inserted\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_info_mysql = read_conn_info('../secrets/mysql-connection.json')\n",
    "conn_str_mysql = MySQLConnector(conn_info=conn_info_mysql).conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql $conn_str_mysql\n",
    "create table test_table (\n",
    "    id char(36) NOT NULL PRIMARY KEY,\n",
    "    name varchar(100),\n",
    "    address varchar(500),\n",
    "    message varchar(1000),\n",
    "    email varchar(100),\n",
    "    test varchar(100),\n",
    "    dob date,\n",
    "    test2 bigint,\n",
    "    test3 float,\n",
    "    test4 text,\n",
    "    created_at timestamp,\n",
    "    updated_at timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n",
      "100000 rows inserted\n"
     ]
    }
   ],
   "source": [
    "inputs = [{\n",
    "    \"conn_info\": conn_info_mysql,\n",
    "    \"table_name\": \"test_table\",\n",
    "    \"db_type\": MySQLConnector,\n",
    "    \"records_num\": 100000\n",
    "} for l in range(10)]\n",
    "for o in inputs:\n",
    "    insert_data(o)\n",
    "    print(\"100000 rows inserted\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "drop table `test.test_table`;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
